{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Examining the context of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concordances\n",
    "\n",
    "As was shown in the previous notebook, lists of frequent words can be very useful. They can help to clarify the main concerns or the themes of a text. \n",
    "\n",
    "To examine *how* words are used in a text, however, it can also be useful to create a concordance. In a concordance, all the occurrences of a given search term are listed in combination with words that occur before and after this term. Such resources are sometimes referred to as *keyword in context* lists (KWIC). \n",
    "\n",
    "The `nltk` package contains a method named `concordance()`. To work with this method, you firstly need to create an instance of the `Text` class. This class is part of the `nltk.text` module. Such a `Text` object can be initialised using a list with all the tokens of a text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.text import Text\n",
    "import os\n",
    "\n",
    "path = os.path.join('Corpus','PrideAndPrejudice.txt')\n",
    "\n",
    "with open( path , encoding = 'utf-8') as file:\n",
    "    full_text = file.read()\n",
    "\n",
    "tokens = word_tokenize(full_text)\n",
    "novel = Text(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, the `Text` object is given the name `novel`. \n",
    "\n",
    "Once you have created such an object, you can use its `concordance()` method. You can supply three parameters: \n",
    "\n",
    "1. A search term.\n",
    "2. A `width` parameter, specifying the extent of the context. With this parameter, you indicate the number of characters before and after the word whose context you want to see. \n",
    "3. A `lines` parameter, which specifies the number of results. \n",
    "\n",
    "Out of these parameters, only the first one is mandatory. When you leave out the last two parameters, the method will work with its default values: a width of 70 (35 characters before and 35 characters after the search term) and 25 lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 66 matches:\n",
      "month . Happiness in marriage is entirely a matter\n",
      "ng of their supposed marriage , and planning his h\n",
      " well disposed of in marriage . This gallantry was\n",
      "probability of their marriage was exceedingly agre\n",
      "the felicity which a marriage of true affection co\n",
      "hat another offer of marriage may ever be made you\n",
      "for happiness in the marriage state . If therefore\n",
      "made you an offer of marriage . Is it true ? '' El\n",
      "ll—and this offer of marriage you have refused ? '\n",
      "using every offer of marriage in this way , you wi\n"
     ]
    }
   ],
   "source": [
    "novel.concordance('marriage' , width = 50 , lines = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `concordance()` method that is defined in `nltk`, the width of the context is defined using a specific number of characters. When you work with such a fixed number of characters, the search term can be shown at the same position on each line, resulting in a keyword-in-context list with a nice and orderly appearance.\n",
    "\n",
    "The downside of this approach is that the various lines may contain incomplete words. Which you indicate that the size of the context must be set at 20 characters before and after the term, the code simply removes all characters preceding or following the twentieth character. \n",
    "\n",
    "The cell below contains a definition of a method which can create a somwhat different type of concordance. In this method, named `concordance_words()`, the width of the context is specified using words rather characters. When you supply the number 10 as the value for the parameter defining the width, you will receive all occurrences of the search term, together with 5 words before and 5 words after this search term. The method demands a sting as input. This string can be the full text of a novel. \n",
    "\n",
    "The results are returned as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from tdmh import *\n",
    "\n",
    "\n",
    "def concordance_word( text, regex , width = 10 ):\n",
    "\n",
    "    concordance = []\n",
    "    distance = math.floor( width /2 )\n",
    "\n",
    "    segment_length = 0\n",
    "\n",
    "    words = word_tokenize( text )\n",
    "    words = remove_punctuation( words )\n",
    "    i = 0\n",
    "    for w in words:\n",
    "        if re.search( regex , w , re.IGNORECASE ):\n",
    "            match = ''\n",
    "            for x in range( i - distance , ( i + distance ) + 1 ):\n",
    "                if x >= 0 and x < len(words):\n",
    "                    if len(words[x]) >= 0:\n",
    "                        match += words[x] + ' '\n",
    "            concordance.append( match )\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return concordance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below contains an illustration of how you can use this method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 67 ocurrences of the word \"marriage\".\n",
      "Here are the first 5 occurrences:\n",
      "\n",
      "\n",
      "studying his character for a twelvemonth Happiness in marriage is entirely a matter of chance If the \n",
      "\n",
      "disliking her guest by talking of their supposed marriage and planning his happiness in such an alliance \n",
      "\n",
      "all in due time well disposed of in marriage This gallantry was not much to the taste \n",
      "\n",
      "her to understand that the probability of their marriage was exceedingly agreeable to her Elizabeth however did \n",
      "\n",
      "very house in all the felicity which a marriage of true affection could bestow and she felt \n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join('Corpus', 'PrideAndPrejudice.txt')\n",
    "\n",
    "\n",
    "with open(path , encoding = 'utf-8') as file:\n",
    "    full_text = file.read()\n",
    "    \n",
    "fragments = concordance_word( full_text , r'marriage' , 16)\n",
    "\n",
    "print( f'There are {len(fragments)} ocurrences of the word \"marriage\".')\n",
    "\n",
    "number_of_results = 5\n",
    "\n",
    "print( f'Here are the first {number_of_results} occurrences:\\n\\n')\n",
    "for f in fragments[:number_of_results]:\n",
    "    print( f'{f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the definition of `concordance_word()`, you can see that the method searches for occurrences of the supplied search term as a regular expression. The second parameter of this method can also be a more complicated regular expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = concordance_word(full_text , r'(\\bhates?\\b)|(\\bloves?\\b)' , 25)\n",
    "\n",
    "for f in fragments[15:22]:\n",
    "    print( f'{f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocation analysis\n",
    "\n",
    "Collocation analyses focus on the words that are used in the vicinity of a provided search term. It may be viewed as an extension of the principle underlying the creation of concordances. To perform a collocation analysis, we can look at the environments of a search term through a 'window' consisting of a given number of words. The words that are used in this context can obviously be counted. The aim of a collocation analysis is to identify the words that are used most frequently in the neighbourhood of a given word. \n",
    "\n",
    "Such collocation analyses can be carried out using the `collocation()` method that is defined below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collocation( text , regex , width ):\n",
    "\n",
    "    freq_c = dict()\n",
    "    distance = math.floor(width/2)\n",
    "\n",
    "    sentences = sent_tokenize( text )\n",
    "\n",
    "    for sentence in sentences:\n",
    "\n",
    "        words = word_tokenize( sentence )\n",
    "        words = remove_punctuation(words)\n",
    "\n",
    "        for i,w in enumerate(words):\n",
    "            if re.search( regex , w , re.IGNORECASE ):\n",
    "                index_regex = i \n",
    "\n",
    "                for x in range( i - distance , i + distance ):\n",
    "                    if x >= 0 and x < len(words) and words[x].lower() != words[index_regex].lower():\n",
    "                        if len(words[x]) > 0:\n",
    "                            word = words[x].lower()\n",
    "                            freq_c[ word ] = freq_c.get( word , 0 ) + 1\n",
    "            \n",
    "    return freq_c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters are the same as those of the `concordance_word()` method: \n",
    "\n",
    "1. The text that needs to be analysed.\n",
    "2. A search term, which will be treated as a regular expression.\n",
    "3. A number representing the width of the context (or, ot be more precise: the number of words). \n",
    "\n",
    "This function returns a dictionary listing all the words found near the search term that is provided, together with the frequencies of these words.  \n",
    "\n",
    "The code below makes use of the function `sortedByValue()` which can sort a dictionary by value, and the list of stopwords from `nltk` to remove the function words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nearby_words = collocation( full_text , r'marriage' , 20)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "nearby_words_sorted = sortedByValue( nearby_words , ascending = False)\n",
    "\n",
    "for word in list( nearby_words_sorted.keys() ):\n",
    "    freq = nearby_words_sorted[word]\n",
    "    if word not in stopwords and freq > 2:\n",
    "        print( f'{word} => {freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cooccurrence\n",
    "\n",
    "Once you have established that two specific words are often used in combination, you can begin to study specific combinations of words in more detail using the `cooccurrence()` method that is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cooccurrence( text , word1 , word2 , width ):\n",
    "    \n",
    "    relevant_sentences = []\n",
    "    \n",
    "    text = re.sub( '\\s+' , ' ' , text )\n",
    "    sentences = sent_tokenize( text )\n",
    "\n",
    "    for s in sentences:\n",
    "        if re.search( r'\\b' + word1 + r'\\b' , s , re.IGNORECASE ) and re.search( r'\\b' + word2 + r'\\b' , s , re.IGNORECASE ):\n",
    "\n",
    "            words = word_tokenize(s)\n",
    "            word1_indexes = []\n",
    "            word2_indexes = []\n",
    "            \n",
    "            for i,w in enumerate(words):\n",
    "                if re.search( r'\\b' + word1 + r'\\b' , w , re.IGNORECASE ):\n",
    "                    word1_indexes.append(i)\n",
    "                elif re.search( r'\\b' + word2 + r'\\b' , w , re.IGNORECASE ):\n",
    "                    word2_indexes.append(i)\n",
    "\n",
    "            if word1_indexes[0] > word2_indexes[0]:\n",
    "                difference = word1_indexes[0] - word2_indexes[0]\n",
    "            else:\n",
    "                difference = word2_indexes[0] - word1_indexes[0]\n",
    "\n",
    "            if difference <= width:\n",
    "                relevant_sentences.append(s)\n",
    "    return relevant_sentences\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The useage of the method is as follows:\n",
    "    \n",
    "* As the first parameter, you mus provide the full text that you want to analyse, as a single string.\n",
    "* As the second and the third parameter, you need to mention the two words that you are interested in. \n",
    "* How close should these two words be? The fourth parameter specifies the number of words that are allowed in between the two words you focus on.  \n",
    "\n",
    "The method `cooccurrence()` returns all the sentences containing the two words that you focus on. The distance (measured in number of words) will not be greater than the width that you specified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = cooccurrence( full_text , 'marriage' , 'lydia' , 10 )\n",
    "\n",
    "for s in sentences:\n",
    "    print( f'{s}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1\n",
    "\n",
    "Create a concordance for the word 'river' in the novel *Heart of Darkness*. You can find the full text in the 'Corpus' folder. Work with a width of 50 characters (i.e. 25 characters before and 25 characters after this search term).\n",
    "\n",
    "Note that all the new functions that have been explained in this notebook have also been defined in the package `tdmh`. Top use these methods, you need to import them first. \n",
    "\n",
    "`from tdmh import *`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdmh import *\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.text import Text\n",
    "\n",
    "import os \n",
    "path = os.path.join('Corpus', 'HeartofDarkness.txt')\n",
    "\n",
    "\n",
    "with open(path, encoding = 'utf-8') as file:\n",
    "    full_text = file.read()\n",
    "\n",
    "#what's the difference between the above and the code below?    \n",
    "#novel = open(path, encoding = 'utf-8')\n",
    "#full_text = novel.read()\n",
    "\n",
    "tokens = word_tokenize(full_text)\n",
    "novel = Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 53 matches:\n",
      " being bound down the river , the only thing for \n",
      "eaward . On the whole river there was nothing tha\n",
      "re profound . The old river in its broad reach re\n",
      "ed on the ebb of that river into the mystery of a\n",
      "ight came out of this river since—you say Knights\n",
      "ina—and going up this river with stores , or orde\n",
      " Flames glided in the river , small green flames \n",
      "ht upon the sleepless river . We looked on , wait\n",
      " , how I went up that river to the place where I \n",
      "t there was in it one river especially , a mighty\n"
     ]
    }
   ],
   "source": [
    "novel.concordance('river' , width = 50 , lines = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2. \n",
    "\n",
    "Create a concordance for the word 'darkness' in the novel Heart of Darkness. This time, work with a width of 20 words (i.e. 10 words before and 10 words after this search term). Display the first 15 occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3\n",
    "\n",
    "Create a concordance for all occurrences of the following words in the novel *Heart of Darkness*:\n",
    "\n",
    "* murky\n",
    "* shadowy \n",
    "* gloomy\n",
    "* brooding\n",
    "\n",
    "To do this, provide a regular expression containing these words as the second parameter for the `concordance_word()` function. Work with a width of 20 words (i.e. 10 words before and 10 words after this search term). Display the first 15 occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4\n",
    "\n",
    "In *Heart of Darkness*, which words are used most frequently in the vicinity of the word 'Kurtz'? Consider 8 words before and 8 words after all the occurrences of this specific word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5\n",
    "\n",
    "Find all the sentences in *Heart of Darkness* contain the words 'heart' and 'darkness'. Make sure that, in these sentences, there are no more than 5 words in between these two words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
